# Chapter 17. 스파크 배포 환경

## 스파크에서 지원하는 클러스터 매니저
2017년 12월 기준, 스파크는 공식적으로 세 가지 클러스터 매니저를 지원합니다:

- 스탠드얼론 모드
- 하둡 YARN
- 아파치 메소스

각 클러스터 매니저는 스파크 애플리케이션을 효율적으로 실행하고 관리하기 위한 도구입니다. 사용자는 환경에 따라 적합한 클러스터 매니저를 선택하고 설정해야 합니다.

### 17.1 스파크 애플리케이션 실행을 위한 클러스터 환경
스파크 클러스터 환경은 크게 두 가지로 나눌 수 있습니다:

#### 설치형 클러스터 (On-Premise Cluster)

데이터 센터 또는 로컬 환경에서 클러스터를 구축하여 사용하는 방식입니다.
- 장점: 데이터가 내부적으로 관리되어 보안성이 높음.
- 단점: 설정 및 유지보수가 복잡하며, 비용과 자원이 많이 소요될 수 있음.
- 중요 고려사항:
    - 복제 시스템 (Replication System): 장애 대비를 위한 데이터 복제 필요.
    - 복구 시스템 (Disaster Recovery System): 데이터 손실 방지를 위한 복구 계획 필수.

#### 클라우드 배포 환경 (Public Cloud)

클라우드 서비스를 활용하여 유연하게 스파크 애플리케이션을 실행.
- 장점: 초기 비용이 낮고 확장이 용이함.
- 단점: 장기적으로 비용이 증가할 수 있음.
- 활용 사례:
    - GPU 기반 작업에서 효율적 활용 가능.
    - 대규모 데이터 관리 및 분석에 적합.

### 17.2 클러스터 매니저

스파크에서 제공하는 클러스터 매니저는 다음과 같은 역할을 합니다:

- 클러스터 환경에서 스파크 애플리케이션을 실행하고 관리하기 위한 핵심 컴포넌트.

- 스탠드얼론 모드, 하둡 YARN, 아파치 메소스를 포함한 다양한 클러스터 매니저를 지원.

#### 17.2.1 스탠드얼론 모드

- 정의: 스탠드얼론 모드는 스파크 전용 클러스터 매니저로, 간단하게 설정할 수 있는 독립적인 환경을 제공합니다.
- 특징:
    - 설정이 간단하며 다른 외부 도구에 의존하지 않음.
    - 확장성은 제한적이지만 소규모 클러스터에서 적합.
- 사용 방식:
    - 클러스터 노드를 설정하고 $SPARK_HOME/sbin/start-master.sh 명령어로 실행.
    - 마스터와 워커 노드 간의 통신을 통해 작업을 관리.

- 클라우드 배포 환경
    - 클라우드 환경에서는 설치형 클러스터와 달리 간단한 설정으로 확장 가능한 인프라를 제공.
    - 대표적인 예로 AWS, Azure, GCP와 같은 클라우드 서비스가 언급됨.

    - 장점:
        - 초기 설정 비용이 낮음.
        - 대규모 데이터 처리를 위한 유연한 확장 가능.
    - 주의 사항:
        - 데이터 저장소와 복제 설정을 통해 안정성을 확보해야 함.

- 스탠드얼론 모드 클러스터 설정

    - 스탠드얼론 클러스터는 애플리케이션 튜닝을 위해 여러 설정이 필요합니다.
    - 설정은 종료된 애플리케이션의 작업 파일 메모리 확보와 메모리 리크 방지를 목표로 합니다.
    - 세부적인 내용은 스파크 공식 문서에서 제공됩니다.
        - 애플리케이션 제출하기
    - 클러스터 마스터 프로세스의 URI (spark://)를 활용하여 애플리케이션 제출 가능.
    - 마스터와 워커 노드 간 통신을 통해 작업이 관리되며, 작업 제출 시 spark-submit 명령을 활용.
    - 스크립트를 이용한 클러스터 시작 및 정지
    - $SPARK_HOME/sbin/start-master.sh: 마스터 인스턴스를 시작.
    - $SPARK_HOME/sbin/start-slaves.sh: 모든 워커 노드를 시작.
    - $SPARK_HOME/sbin/stop-master.sh: 마스터 인스턴스를 중지.
    - $SPARK_HOME/sbin/stop-slaves.sh: 모든 워커 노드를 중지.

#### 17.2.2 YARN에서 스파크 실행하기

- 하둡 YARN은 잡 스케줄러로, 자원 관리와 병렬 실행을 지원.
- 스파크는 YARN 위에서 애플리케이션 실행 가능하며, 분산 환경에서 확장성 제공.


- 애플리케이션 제출하기
    - YARN 클러스터에서는 spark-submit 명령어와 --master yarn 옵션을 사용하여 애플리케이션을 실행합니다.
    - 설정 파일은 YARN 환경변수인 HADOOP_CONF_DIR을 통해 지정할 수 있습니다.
    - 설정이 완료되면 YARN 클러스터에서 애플리케이션이 실행되며, 작업이 분산 처리됩니다.

- 하둡 설정
    - 스파크는 HDFS와의 연계를 위해 하둡 설정 파일(core-site.xml 등)을 필요로 합니다.
    - 설정 파일은 $HADOOP_CONF_DIR 환경변수에 경로를 지정해 사용합니다.
    - 명령어 실행 시 해당 설정이 반영되어야 하며, 작업 제출 전에 환경 설정을 확인해야 합니다.
- YARN 애플리케이션 속성
    - YARN 설정은 보안, 성능, 확장성 등 스파크 애플리케이션 실행에 영향을 미칩니다.
    - 관련 설정은 스파크 공식 문서에서 확인할 수 있습니다.

#### 17.2.4 메소스에서 스파크 실행하기

- 아파치 메소스는 또 다른 클러스터 매니저로, 분산된 시스템에서 작업을 관리합니다.
- 메모리, 스토리지, 네트워크 자원을 효율적으로 관리하며 높은 확장성과 안정성을 제공합니다.


#### 17.2.5 보안 관련 설정

- 스파크는 보안 수준이 낮은 환경에서도 애플리케이션을 안전하게 실행하기 위해 SSL, 인증, 네트워크 암호화(TLS) 설정 등을 제공합니다.
- 관련 설정은 스파크 공식 문서의 보안 설정 섹션을 참조해야 합니다.

#### 17.2.6 클러스터 네트워크 설정

- 클러스터 내 노드 간 통신을 최적화하기 위해 프록시(proxy)를 활용하여 배포 시나리오에 맞는 설정을 적용할 수 있습니다.
- 설정은 클러스터 성능을 향상시키며 네트워크 병목 현상을 방지합니다.

#### 17.2.7 애플리케이션 스케줄링
- 스파크는 여러 작업 과정에서 필요한 자원을 스케줄링하여 효율적으로 관리할 수 있는 기능을 제공합니다.
- 주요 스케줄링 기능:
    - 독립적인 인스턴스에서 프로세스를 실행.
    - 페어 스케줄러를 통해 네트워크 자원을 최적화.
    - 자세한 내용은 공식 문서의 스케줄링 설정 섹션에서 확인할 수 있습니다.
- 동적 할당
    - 스파크는 사용하지 않는 자원을 동적으로 재할당하여 클러스터 자원을 효율적으로 활용하는 기능을 제공합니다.
    - 이 기능은 spark.dynamicAllocation.enabled 속성을 활성화하여 사용할 수 있으며, 클러스터 매니저에 따라 설정이 달라집니다.
