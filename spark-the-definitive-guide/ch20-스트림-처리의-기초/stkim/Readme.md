# Chapter 20. 스트림 처리의 기초

## 도입부

- 스트림 처리의 중요성 
   - 빅데이터 애플리케이션에서 스트림 처리는 핵심 기능이며, 기업들은 고객 활동 분석이나 머신러닝 모델 개선을 위해 이를 도입하고 있음.
   - chatgpt에서도 스트리밍 API가 매우 중요하다고 소개하고 있음.

- 아파치 스파크의 스트림 처리 지원  
   - 2012년에 **Spark Streaming**과 **DStream API**를 도입하여 `map`, `reduce` 같은 연산자로 스트림 데이터를 처리할 수 있도록 함.  
   - 많은 기업들이 대규모 실시간 애플리케이션을 위해 **DStream**을 사용하며, 시간당 테라바이트 이상의 데이터를 처리하는 경우도 많음.  

- DStream API의 한계
   - RDD API와 마찬가지로 DStream은 **자바나 파이썬 객체 기반**이라 최적화된 연산을 수행하는 데 제약이 있음.  

- 구조적 스트리밍(Structured Streaming) 도입
   - 2016년, **DataFrame과 Dataset 기반**의 **구조적 스트리밍(Structured Streaming)**이 추가됨.  
   - 더 높은 최적화가 가능하고, 코드 통합이 쉬워짐.  
   - **Spark 2.2** 버전에서 안정화되어 빠르게 확산됨.  



## **20.1 스트림 처리란**
- **스트림 처리(stream processing)**는 데이터를 **끊임없이 처리하여 결과를 생성**하는 방식.  
- 스트림 입력 데이터는 무한하며 시작과 끝이 정해져 있지 않음.  
- 스트림 데이터는 웹사이트 클릭, IoT 센서 데이터 등 **실시간 이벤트 기반**으로 들어옴.  
- 스트림 애플리케이션은 연속적으로 실행되며, 다양한 쿼리를 수행함.  
- 결과는 외부 **"sink"**에 저장될 수도 있음.

- 스트림 처리는 **배치 처리와 비교**할 수 있음.  
  - 배치 처리는 **고정된 데이터**를 처리하는 방식.  
  - 일반적인 배치 작업은 일정 주기로 실행되지만, **스트림 처리는 실시간으로 데이터를 지속적으로 분석**함.  

- 스트림 애플리케이션은 배치 작업처럼 정기적으로 실행되는 경우도 있음.  
  - 예를 들어, **스트림 데이터를 특정 시점에서 조회하는 경우도 가능**.

### **20.1.1 스트림 처리 사례**
- **스트림 처리를 활용하는 대표적인 사례 6가지**를 소개.

**통보와 알림**  
- **연속적인 이벤트 감지** 후 특정 패턴이 감지되면 즉시 알림을 제공.  
- 예) **물류 창고에서 특정 조건을 만족하면 즉시 직원에게 알림**을 보내는 시스템.  
- 알림은 빠르게 전달될 필요가 있음.

**실시간 리포트**  
- **기업 내 직원들이 실시간으로 데이터를 확인**할 수 있도록 스트리밍 시스템을 구축.  
- 데이터는 지속적으로 업데이트됨.  


**중분류 ETL (Extract, Transform, Load)**
- 기업들은 데이터 웨어하우스에서 정보를 조회하는 속도를 높이기 위해 **스트리밍 ETL**을 사용.  
- 스트리밍을 활용하면 원시 데이터를 빠르게 구조화하여 변환 및 저장 가능.  
- **Exactly-once 처리**(데이터 중복 없이 정확한 변환) 보장이 필수적.  
- 스트리밍 시스템은 **트랜잭션을 유지하면서 데이터 웨어하우스를 갱신**해야 함.


**실시간 제공용 데이터 갱신**
- 스트리밍 시스템은 **분석 시스템의 실시간 데이터 갱신**에 사용됨.  
- 예) **웹사이트 방문자 수 실시간 집계**, 최신 방문자를 빠르게 조회 가능.  
- 기존 배치 작업보다 **빠르고 적은 리소스로 운영 가능**.


**실시간 의사결정**
- **신용카드 거래 사기 탐지**와 같은 **실시간 의사결정**에 활용됨.  
- 비정상적인 패턴을 감지하여 자동으로 비즈니스 로직을 적용.  
- 예) **고객 소비 패턴을 분석하여 사기 거래 차단**.  
- 빠른 반응이 필요한 트랜잭션 기반 서비스에서 유용.

**온라인 머신러닝**
- **실시간 데이터 학습**을 통해 **모델을 지속적으로 갱신**.  
- 예) **고객의 최근 거래 데이터를 반영한 신용 평가 시스템**.  
- **전체 고객 데이터를 한 번에 갱신하지 않고, 점진적인 업데이트 방식 사용**.  
- 빠른 응답 속도를 요구하는 머신러닝 시스템에서 활용됨.

**20.1.2 스트림 처리의 장점**

**처리 시간이 짧다**  
   - 배치 처리보다 빠르게 데이터를 분석 및 저장 가능.  
   - 실시간 대응이 필요한 환경에서 필수적.

**데이터 효율성이 높다**  
   - 배치 시스템은 일정 주기로 데이터 전체를 처리해야 하지만,  
     스트리밍 시스템은 **새로운 데이터만 반영하여 효율적으로 업데이트**.  
   - 예) **실시간 재고 관리 시스템**에서 새로운 입출고 데이터만 반영하여 최적화.

**자동화된 의사결정 지원**  
   - **24시간 자동화된 분석 및 의사결정**이 가능.  
   - 배치 시스템은 일정 주기로 결과를 제공하지만,  
     스트리밍 시스템은 **실시간으로 이상 탐지 및 대응** 가능.

### **20.1.3 스트림 처리의 과제**
- 스트림 처리 시스템을 운영하면서 발생할 수 있는 **문제점과 해결 과제**를 설명.
- 센서를 통해 **시간마다 생성되는 데이터를 수신하는 애플리케이션**을 가정.
- 입력 데이터가 **지연되거나 재전송될 경우** 문제가 발생할 수 있음.  
  - 예) 특정 값이 순서가 뒤바뀌거나, 같은 데이터가 중복해서 들어오는 문제.  
  - 데이터를 순서대로 정렬하는 배치 처리와 다르게 **스트림 처리는 데이터 순서가 보장되지 않음**.

- **스트림 처리에서 발생하는 주요 문제**
   - **입력 데이터의 순서가 뒤바뀜**
   - **대규모 상태 정보 유지 어려움**
   - **높은 데이터 처리량 보장 필요**
   - **장애 발생 시 정확한 복구 어려움**
   - **데이터 중복 및 누락 문제**
   - **다른 저장소 시스템과의 통합 문제**
   - **출력 시스템과 데이터 동기화 문제**
   - **비즈니스 로직 변경 어려움**

## **20.2 스트림 처리의 핵심 설계 개념**
- 높은 처리량, 빠른 처리, 데이터 순서 보장 등의 문제를 해결하기 위한 **설계 개념**을 다룸.
- **스트림 처리의 일반적인 설계 패턴**을 설명.

#### **20.2.1 레코드 단위 처리와 선언형 API**
- 스트리밍 API에서 **가장 단순한 방식**은 **각 이벤트를 애플리케이션에 전달**하여 처리하는 방법.  
  - 예) **Apache Storm**과 같은 전통적인 스트리밍 시스템.  
- 하지만 이러한 방식은 **상태 관리와 트랜잭션 보장이 어렵고**, 개발자가 직접 메모리와 동기화를 관리해야 함.
- 최신 스트리밍 시스템은 **선언형 API**를 사용하여 이런 문제를 해결함.
  - **필터(filter), 맵(map), 리듀스(reduce)** 등의 연산을 제공하여 **SQL과 유사한 방식**으로 데이터 처리 가능.

### **20.2.2 이벤트 시간과 처리 시간**
- **이벤트 시간**: 원본 시스템에서 생성된 시점을 기반으로 데이터 처리.  
- **처리 시간**: 스트리밍 시스템이 데이터를 수신한 시점 기반 처리.  
- 데이터 전송 지연으로 인해 **이벤트 시간과 처리 시간 차이가 발생할 수 있음**.  
- 일부 데이터는 **순서가 뒤섞이거나, 지연되어 수신될 가능성이 있음**.

### **20.2.3 연속형 처리와 마이크로 배치 처리**
- **연속형 처리**: 노드 간 메시지를 바로 전달하여 처리하는 방식.  
- **마이크로 배치 처리**: 일정한 크기의 데이터를 모아서 배치 처리.  
- 연속형 처리는 빠른 반응이 가능하지만, **고정된 처리량을 유지하기 어려움**.  
- 마이크로 배치는 안정성이 높지만, 지연 시간이 발생할 수 있음.  
- 일반적으로 **연속형 처리와 마이크로 배치를 적절히 조합**하여 운영.


## **20.3 스파크의 스트리밍 API**
- 스파크는 **DStream API**와 **구조적 스트리밍 API** 두 가지 스트리밍 방식을 제공.
- **DStream API**는 기존 마이크로 배치 방식과 유사하며, **이벤트 시간 처리**를 지원하지 않음.
- **구조적 스트리밍 API**는 **최적화된 기술, 이벤트 시간, 연속적 처리**를 지원하는 방식.

### **20.3.1 DStream API**
- **2012년에 최초 공개**, 2016년까지 **가장 널리 사용된 스트림 엔진**.
- RDD 인터페이스를 기반으로 작동하며, **기존 배치 애플리케이션과 통합이 용이**.
- 단점:
  1. **RDD 기반으로 동작**하여 **최적화된 기술 적용이 어려움**.
  2. 이벤트 시간이 아닌 **처리 시간**을 기준으로 동작.
  3. **마이크로 배치 주기 기반**으로 실행되므로, 연속적인 스트림 처리가 어려움.

### **20.3.2 구조적 스트리밍**
- 스파크의 **구조적 API**를 활용한 **고급 스트리밍 API**.
- **SQL 및 DataFrame API를 기반**으로 동작.
- 기존 **DStream과 달리 이벤트 시간 기반 처리 지원**.
- 2.2 버전에서는 **마이크로 배치 방식만 지원**, 2.3 버전부터 **연속적 처리(Continuous Processing) 기능 추가**.
- 데이터가 도착할 때마다 자동으로 연산을 수행하며, **일반적인 배치와 스트리밍을 하나의 프레임워크로 통합** 가능.
