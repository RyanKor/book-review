# 데이터 소스

## 1. 데이터소스 API 구조

### 1.1 읽기 API 구조

- 기본 포맷은 Parque 사용

### 1.2 데이터 읽기의 기초

- DataFrameReader를 사용하고, SparkSession의 read 속성 사용

### 1.3 쓰기 API 구조

- partitionBy, BucketBy, SortBy

### 1.4 데이터 쓰기의 기초

- DataFrameWriter를 사용

- 저장 모드

    - append
    - overwrite : 기록하고자 하는 폴더 내부의 모든 파일 새로 write (아... 이것 때문에 예제 데이터셋 날아감..)
    - errorIfExist
    - ignore

## 2. CSV 파일

- 컬럼에 콤마가 있거나 비표준적 방식으로 null 입력되면, 이스케이프 문자로 처리 가능

### 2.1 CSV 옵션

- 크게 어렵거나 잘 안와닿는 옵션은 없음 250p 참고.

### 2.2 CSV 파일 읽기

- 비정상 데이터를 얼마나 수용할 수 있을지 선택해서, 읽기 수행 가능함

### 2.3 CSV 파일 쓰기

- 어려운 내용 없음. pandas 쓰듯이 비슷함. 사실 분산처리할 때 쓰기 어떻게 하는지가 더 궁금한뎀...

## 3. Json 파일

- Json은 객체라 CSV 보다 메서드 옵션이 적음

### 3.1 Json 옵션

- pass

### 3.2 Json 파일 읽기

- pass

### 3.3 Json 파일 쓰기

- pass

## 4. Parque 파일

- 분석 워크로드 최적화

### 4.1 Parque 옵션

- 거의 없음. 데이터 저장할 때 자체 스키마 사용함.

### 4.2 Parque 파일 읽기

- CSV와 비슷하게 읽는 시점에 스키마를 알 수 있음. 컴파일러 실행 시점에 확인 불가.

### 4.3 Parque 파일 쓰기

- pass

## 5. ORC 파일

- 대규모 스트리밍, 찾고자하는 Row 탐색에 최적화 (컬럼 기반 타입 포맷으로 하둡 워크로드에 최적화)
- parque는 스파크, ORC는 하이브에 최적화 되어 있음

### 5.1 ORC 파일 읽기

- pass

### 5.2 ORC 파일 쓰기

- pass

## 6. SQL DB

- JDBC 드라이버 기반으로 세션 연결 가능.

### 6.1 SQL DB 읽기


- pass

### 6.2 쿼리 푸시 다운

- DataFrame 구성 전에 DB에서 데이터를 자체 필터링 가능

- 문제는 스파크에서는 모든 DB에 맞춰서 함수를 변환하지 못하기 때문에 때로는 전체 쿼리에 대해 요청을 할 때도 있음

- DB 병렬로 읽기 : numPartitions를 사용해서 한 번에 읽기/쓰기 수행할 수 있는 최대 파티션 갯수 조절 가능.

- 슬라이딩 윈도 개념의 파티셔닝 : 개념이 잘 안와닿음. 슬라이딩 윈도우 개념을 파티셔닝에 도입해 병렬처리한다는 것 같은데, 뭘 기준으로 슬라이딩 윈도우를 하는가?

### 6.3 SQL DB 쓰기

- pass

## 7. 텍스트 파일

- 로그 파일, 자연어?

### 7.1 텍스트 파일 읽기

- textFile 메서드 사용

### 7.2 텍스트 파일 쓰기

- text 메서드 사용

## 8. 고급 I/O 개념

### 8.1 분할 가능한 파일 타입과 압축 방식

- 스파크에서 분할해서 파일을 읽는 구조 구성이 가능한데, 모든 파일 포맷에 대해 분할을 지원하지 않음.

### 8.2 병렬로 데이터 읽기

- executor 수 만큼 병렬 읽기 가능하고, 데이터가 더 많으면 그 작업들은 pending

### 8.3 병렬로 데이터 쓰기

- 파티셔닝 : 어떤 데이터를 어떻게 저장할 것인가?

- 버케팅 : 저장된 데이터를 어떻게 조직화할 것인지에 대한 기법. 동일 버킷 ID를 갖고 있는 데이터들은 하나의 물리적 파티션에 모두 모임. 고비용 셔플 및 조인 비용 감소.

### 8.4 복잡한 데이터 유형 쓰기

- CSV 타입 데이터는 복잡한 데이터 쓰기 지원 안함. ORC는 지원

### 8.5 파일 크기 관리

- 스파크는 작은 크기의 파일 다루는 것에 매우 성능이 안좋음.

- 너무 커도 문제임

- 2.2 버전부터 읽거나 쓸 파일의 크기를 조절할 수 있음 (maxRecordsPerFile)

- Row 최대 쓰기 5,000개까지 가능함.