# Chapter 15. 클러스터에서 스파크 실행하기

## 챕터 다 읽고 정리하면서 들었던 생각: 도대체 왜 이걸 이제 설명하나...

## 1. 스파크 애플리케이션의 아키텍처

- 사용자가 코드를 작성하고 Spark 애플리케이션을 실행하면, `드라이버`가 실행되고 클러스터 매니저에 자원을 요청.

- `클러스터 매니저`는 요청된 자원을 기반으로 익스큐터를 시작.

- `드라이버`는 `익스큐터`에 태스크를 분배.

- `익스큐터`는 태스크를 실행하고, 결과를 드라이버로 반환.

- 실행 모드

    - 클러스터 모드 : JAR, Python, R 스크립트 클러스터 매니저에 전달.

    - 클라이언트 모드: 클라이언트 머신에 드라이버 위치.

    - 로컬 모드: 단일머신에서 모든 스파크 애플리케이션 (컨텍스트 매니저, 드라이버, 익시큐터) 실행

## 2. 스파크 애플리케이션 생애주기 (스파크 외부)

### 2.1 클라이언트 요청

- 애플리케이션 제출 시점에 로컬 머신에서 코드가 실행되고, 클러스터 드라이버 노드 요청

- 이 과정에서 드라이버 프로세스의 자원 요청을 클러스터 매니저에 전달.

### 2.2 시작

- 사용자 코드 실행

- 클러스터 매니저 -> 익스큐터 프로세스 실행 요청

- 익스큐터 응답 결과 받아 드라이버 프로세스로 전송

### 2.3 실행

- 드라이버, 워커는 코드 실행 및 데이터 이동 과정에서 서로 통신

### 2.4 완료

- 성공 / 실패

- 클러스터 매니저 -> 드라이버가 속한 클러스터의 모든 익스큐터 종료.

## 3. 스파크 애플리케이션 생애 주기 (스파크 내부)

- 스파크 외부는 인프라 관점이고, 애플리케이션 내부는 다름.

### 3.1 SparkSession

- SparkSession 을 사용해서 스파크 코드를 생성하는 것이 가능함.  (저수준 API, 기존 컨텍스트 및 설정 값)

### 3.2 SparkContext

- SparkSession의 SparkContext는 스파크 클러스터에 대한 연결.

### 3.3 논리적 명령

- 파티션을 재분배하는 Job
- 값을 트랜스포메이션하는 Job
- 집계 및 최종 결과 얻어내는 Job

### 3.4 Spark Job

- 액션 하나 당 하나의 스파크 잡이 생성하며 액션은 항상 결과 반환.

- Job은 일련의 스테이지로 이뤄지고, 스테이지 수는 셔플 작업이 얼마나 많이 발생하느냐에 따라 달라짐.

### 3.5 스테이지

- 다수의 머신에서 동일 연산 수행하는 Task 그룹

- 스파크 알고리즘은 가능한 많은 Task를 동일 스테이지로 묶고자함.

- 셔플 발생 후에는 반드시 새 스테이지 시작함.

    - 왜? 셔플로 데이터가 재분배되면 동일연산 목적으로 데이터를 다시 확인해야하기 때문.

- 경험적으로 스파크 클러스터 사용 중이라면 익시큐터 수보다 파티션이 많아야함.

- 최종 스테이지에서 드라이버로 결과 전송 전에 개별적 수행 결과를 단일 파티션으로 모으는 작업 수행.

### 3.6 Task

- 스테이지는 Task로 구성.

- 단일 익스큐터에서 실행할 데이터의 블록 + 다수 트랜스포메이션 조합.

- 데이터 단위 (파티션)에 적용되는 연산 단위임.

## 4 세부 실행 과정

- map 연산 이후 다른 map 연산 이어지면 함께 실행할 수 있도록 스테이지와 태스크 자동 연결

- 모든 셔플 작업에 있어 데이터를 안정적인 저장소에 저장하기에 여러 Job에서 사용 가능

### 4.1 파이프라이닝

- 노드간 데이터 이동 없이 각 노드가 데이터를 직접 공급할 수 있는 연산만 모아 태스크의 단일 스테이지로 구성.

### 4.2 셔플 결과 저장

- 셔플이 실행되면 소스 태스크의 스테이지 실행 중 셔플 파일로 로컬 디스크에 기록.