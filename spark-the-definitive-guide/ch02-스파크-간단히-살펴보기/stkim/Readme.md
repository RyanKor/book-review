# 2. 스파크 살펴보기

- 스파크는 드라이버, 익스큐터로 구성됨.

- 드라이버는 애플리케이션 수명 주기 관련 정보 유지

- 익스큐터는 드라이버가 할당한 작업 수행.

![참고 이미지](https://github.com/user-attachments/assets/2f444766-d88d-433a-8203-a99c671c08a6)

- 1장에서 얘기했던 것처럼 다양한 언어에서 사용 가능

    - 이게 가능한 이유는 스파크 드라이버가 스파크 세션을 제어하고 있어, 각 언어에서 API 통신이 가능함.

- 스파크 API 2가지

    - 저수준의 비구조적 API
    - 고수준의 구조적 API

- 스파크에서 일정 범위의 숫자를 만드는 간단한 작업을 DataFrame에 담는다면

    - 이는 분산 컬렉션으로 숫자의 각 부분이 서로 다른 익스큐터에 할당됨.
    - (추가 의견) 최근 pandas를 gpu에 태워 학습하는 방식이 언급되는데, 이것도 비슷한 일환일듯
    - https://github.com/rapidsai/cudf

- 스파크에 언급되는 중요 핵심 개념들 (DataSet, DataFrame, SQL, RDD) 모두 분산 데이터 모음을 표현한다.

- 그리고 익스큐터가 병렬로 작업을 수행할 수 있게 `파티션`이라는 청크 단위로 데이터 분할

    - 이건 카프카와 비슷함.

    - 단, DataFrame을 사용하면 파티션을 수동 혹은 개별적으로 처리할 필요 없음.

- 트랜스포메이션(Transformation)

    - 스파크의 데이터 구조 핵심은 `불변성` 임.

    - 한 번 생성한 데이터는 변경이 불가한데, 변경하려면 변경 방법을 스파크에 알려줘야함. 이 때 사용하는 명령이 트랜스포메이션.

    - 두 가지 유형 : 좁은 의존성, 넓은 의존성

    - 좁은 의존성은 각 입력 파티션이 하나의 출력 파티션에 영향을 줌.

    - 넓은 의미는 하나의 입력 파티션이 여러 출력 파티션에 영향을 줌.

- 지연연산 (Lazy Evaluation)

    - 특정 연산 명령이 내려지면 바로 수정하지 않고, 원시 데이터에 적용할 트랜스포메이션 실행 계획 생성.

    - 트랜스포메이션은 스파크 코드 실행 마지막 순간까지 대기하다가 컴파일됨.
    
    - (사견) 지연 연산으로 수정을 마지막에 진행한다는 것은 컴파일 될 때 딱 1회만 수정하겠다는 뜻?

- 액션

    - 트랜스포메이션의 논리적 실행 계획 수립 후, 실제 연산 수행할 때의 명령.

- 종합 예제

    - [소스코드 링크](https://github.com/FVBros/Spark-The-Definitive-Guide/tree/master)

![example image](https://github.com/user-attachments/assets/4e690588-6b53-459b-b253-809f00def9ff)

- `데이터 읽기`: DataFrame은 최초 생성 시 파일을 로드하지만, 실제로 액션(action)이 호출되기 전까지는 데이터를 읽지 않습니다. 이는 트랜스포메이션(transformation)이기 때문에 지연 평가(lazy evaluation)가 적용됩니다.

- `데이터 그룹화`: groupBy 메서드를 통해 특정 컬럼을 기준으로 데이터를 그룹화하고, 그룹화된 결과는 RelationalGroupedDataset으로 반환됩니다. 기본적으로 그룹별 집계 작업이 수행됩니다.

- `집계 함수 적용`: 그룹화된 데이터에 대해 sum과 같은 집계 함수를 적용하여 원하는 컬럼의 합계를 구합니다. 이 과정 역시 트랜스포메이션이기 때문에, 실제로 연산이 일어나지 않습니다.

- `컬럼명 변경`: withColumnRenamed 메서드를 사용하여 컬럼명을 변경합니다. 이 또한 트랜스포메이션 작업으로, 실질적인 연산은 발생하지 않습니다.

- `데이터 정렬`: desc 함수를 사용하여 지정한 컬럼을 기준으로 역순으로 정렬합니다. 이는 컬럼 객체를 반환하며, 트랜스포메이션의 일부로 실제 정렬은 액션 단계에서 수행됩니다.

- `결과 제한`: limit 메서드를 사용해 DataFrame의 결과에서 상위 5개 행만을 반환하도록 제한합니다. 전체 데이터가 아닌 일부만 반환하여 처리할 수 있습니다.

- `액션 수행`: 최종적으로 액션을 호출하여 모든 트랜스포메이션을 실행합니다. 이 단계에서 데이터를 메모리에 로드하며, 처리 결과를 리스트나 배열 형태로 반환합니다. explain 메서드를 통해 실행 계획을 시각화하고 확인할 수 있습니다.

결국 예제에서 설은 Spark에서 트랜스포메이션과 액션을 분리하여 지연 평가와 최적화된 실행을 수행하는 방식으로 이해할 수 있습니다.