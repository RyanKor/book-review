# Chapter 18. 모니터링과 디버깅

---

## 18.1 모니터링 범위

스파크 잡에서 오류가 발생한 지점을 파악하려면 잡을 모니터링해야 합니다. 이 섹션에서는 모니터링 대상과 효과적인 모니터링을 위한 옵션을 설명합니다. 주요 내용은 다음과 같습니다.

### **스파크 애플리케이션과 잡**
- 디버깅을 위해 클러스터에서 실행 중인 사용자 애플리케이션의 상태를 파악하려면 **스파크 UI와 애플리케이션 로그**를 확인해야 합니다.
- 스파크 UI와 로그는 RDD, 쿼리 실행 계획, 실행 수준 등 애플리케이션의 상세 정보를 제공합니다.

### **JVM 모니터링**
- 스파크는 모든 작업을 **자바 가상 머신(JVM)** 위에서 실행합니다. 실행 과정을 이해하려면 JVM 수준의 모니터링이 필요합니다.
- **JVM 도구:**
  - **스택 트레이스(stack trace):** `jstack` 같은 도구를 통해 스택 트레이스를 생성 및 분석할 수 있습니다.
  - **힙 덤프(heap dump):** 메모리 상태를 캡처하여 분석에 활용할 수 있습니다.
  - **보고서 생성:** 다양한 도구에서 주기적인 보고서를 제공하여 JVM 속성과 변수를 분석할 수 있습니다.
  - **콘솔 도구:** `jconsole`, `visualvm` 같은 도구를 사용해 JVM의 쓰레드 및 메모리 동작을 시각적으로 확인할 수 있습니다.

- 스파크 UI는 일부 모니터링 정보를 제공하지만, **정밀한 디버깅**을 위해서는 JVM 수준의 모니터링이 더 효과적입니다.

## 18.2 모니터링 대상

스파크 애플리케이션을 효과적으로 모니터링하고 디버깅하려면 주요 모니터링 대상을 이해해야 합니다. 대상은 크게 다음 두 가지로 나뉩니다:

---

### ** OS와 머신**
- **운영체제 및 호스트 머신 상태**를 지속적으로 확인하는 것이 중요합니다.
  - **모니터링 요소**: CPU, 네트워크, I/O, 메모리.
  - **모니터링 도구**: `dstat`, `iostat`, `iotop` 등을 활용하여 자세히 분석 가능.
- **클러스터 수준 모니터링**도 필요하며, 이를 위해 **Ganglia**나 **Prometheus** 같은 툴을 활용할 수 있습니다.

---

### **클러스터**
- 스파크 애플리케이션은 클러스터에서 실행되므로 클러스터 상태를 모니터링해야 합니다.
  - **모니터링 대상**: YARN, Mesos, Standalone 클러스터 매니저.

---

## 18.2.1 드라이버와 익스큐터 프로세스
- 스파크 애플리케이션 실행 시 **드라이버**와 **익스큐터** 프로세스 상태를 지속적으로 확인해야 합니다.
- **드라이버 모니터링**:
  - JVM 상태를 추적하고 안정적으로 작동 중인지 점검.
  - **Metric 시스템** 활용:
    - `$SPARK_HOME/conf/metrics.properties` 파일에서 설정 가능.
    - 예: `spark.metric.conf`를 통해 다양한 메트릭 값을 전달.
  - **모니터링 도구**: Dropwizard Metrics Library.
- **익스큐터 모니터링**:
  - 익스큐터의 상태를 파악하고 성능 향상에 기여.

---

## 18.2.2 쿼리, 잡, 스테이지, 태스크
- 스파크 실행 작업을 세부적으로 이해하려면 **쿼리**, **잡**, **스테이지**, **태스크**의 개념을 알아야 합니다.
  - 클러스터 뷰에서 특정 쿼리가 실행 중인 작업을 파악하고 개선 가능.
  - **효과**: 성능 모니터링 및 디버깅에 유용.

---

## 18.3 스파크 로그
- **스파크 로그**는 가장 세밀한 수준의 모니터링 도구로 활용 가능.
- 애플리케이션의 다양한 상태를 기록하여 디버깅에 도움을 줌.

### **로그 설정**
- 로그 레벨 설정 예제:
```bash
spark.sparkContext.setLogLevel("INFO")
```

## 18.4.1 스파크 REST API

스파크는 UI 외에도 **REST API**를 통해 스파크의 상태와 메트릭 정보를 확인할 수 있는 기능을 제공합니다.

### **REST API 주요 정보**
- **주소**: `http://localhost:4040/api/v1`
- 스파크에서 제공하는 시각화 및 모니터링 도구는 REST API를 기반으로 제작되었습니다.
- 대부분의 REST API는 스파크 UI와 동일한 정보를 제공하며, SQL 관련 정보는 제공하지 않습니다.

### **REST API 활용**
- 스파크 UI에서 확인 가능한 정보를 기반으로 사용자의 정의된 리포트 솔루션을 구축하려면 REST API를 사용해야 합니다.
- 자세한 내용과 사용법은 [스파크 공식 문서의 REST API 관련 표](https://spark.apache.org/docs/latest/monitoring.html#rest-api)를 참조하세요.

## 18.4.2 스파크 UI 히스토리 서버

스파크 UI는 SparkContext가 실행되는 동안 사용할 수 있습니다. 그러나 **종료 후에도 애플리케이션 정보를 확인하려면 스파크 히스토리 서버(Spark History Server)**를 사용해야 합니다.

### **히스토리 서버 설정 및 활용**
- **이벤트 로그 저장**:
  - `spark.eventLog.enabled`를 `true`로 설정.
  - `spark.eventLog.dir` 속성을 통해 이벤트 로그 저장 경로 지정.
- 저장된 로그는 스파크 히스토리 서버에서 웹 UI로 재구성하여 확인 가능.
- 클러스터 매니저나 클라우드 서비스에서 자동으로 설정된 경우도 있음.

### **추가 정보**
- 스파크 공식 문서에서 히스토리 서버 설정에 대한 내용을 확인하세요.

---

## 18.5 디버깅 및 스파크 응급 처리

스파크 애플리케이션 실행 중 **에러 및 응급 상황에 대응하기 위한 디버깅 방법**을 제공합니다. 여기에는 `OutOfMemoryError` 등 주요 에러와 해결 방안을 포함합니다.

---

### **18.5.1 스파크 애플리케이션이 시작되지 않는 경우**

#### **증상**
- 스파크 잡이 시작되지 않음.
- 스파크 UI가 드라이버 또는 제한된 정보만 표시.
- 스파크 UI가 잘못된 정보를 제공.

#### **대응 방법**
- **원인 파악**:
  - 자원 부족, 네트워크 문제, 포트 충돌 등 클러스터 환경 문제 가능.
- **해결책**:
  - 포트 번호 확인 및 충돌 방지.
  - 자원 설정 확인 (예: 드라이버와 익스큐터에 충분한 메모리와 CPU 제공).
  - `spark-submit` 명령을 통해 클러스터 매니저 로그 확인.

---

### **18.5.2 스파크 애플리케이션 실행 중 오류**

- 새로 작성된 애플리케이션을 클러스터 환경에서 실행할 때 자주 발생.
- 정확한 원인과 해결 방안은 에러 로그를 통해 확인 가능.

### 18.5.3 스파크 애플리케이션 실행 중에 오류가 발생한 경우

#### **징후와 증상**
- 하나의 스파크 잡이 전체 클러스터에서 성공적으로 실행되지 않고 다음 작업이 실패합니다.
- 여러 단계로 처리되는 쿼리의 특정 단계가 실패합니다.
- 예제 정상 동작을 위한 작업이 오류로 실패합니다.
- 오류 메시지를 출력하며 종료됩니다.

#### **잠재적 대응법**
1. **데이터 검증**:
   - 데이터가 존재하지 않거나, 데이터 입력이 올바른지 확인합니다.
   - 포맷이 변경되었거나 일부 처리 과정에서 변형된 경우를 검토합니다.

2. **클러스터 구성 확인**:
   - 스파크 애플리케이션이 의도하지 않은 클러스터 자원을 호출했는지 점검합니다.
   - 사용 중인 라이브러리, 네트워크 연결 상태, 데이터 스키마의 적합성 확인이 필요합니다.

3. **쿼리 실행 계획 검토**:
   - 실행 단계에서 발생할 수 있는 문제를 `stack trace` 분석으로 파악합니다.
   - 쿼리에서 잘못된 조합이 실행되었는지 확인합니다.

4. **디버깅 및 로그 활용**:
   - 로그 파일을 통해 문제 발생 지점을 추적합니다.
   - 문제 해결을 위한 추가 레코드를 삽입하거나 코드를 세부적으로 확인합니다.

---

### 18.5.4 느리거나 뒤처진 태스크

#### **징후와 증상**
- 스파크 스테이지에서 대부분의 태스크가 정상적으로 실행되지만 소수의 태스크만 남아있음.
- 여러 스테이지에서 반복적으로 느린 태스크가 발견됨.
- 특정 태스크가 다른 태스크에 비해 훨씬 오랜 시간 실행됨.
- 스파크 메트릭을 보면 특정 익스큐터가 많은 데이터를 읽거나 쓰는 현상이 발견됨.

#### **잠재적 대응법**
1. **데이터 균등 분배 확인**:
   - 데이터의 편중(데이터 스큐)을 방지하기 위해 데이터를 다시 파티셔닝하거나 재분배합니다.

2. **하드웨어 문제 점검**:
   - 특정 노드가 과부하 상태인지, 하드웨어 자원(디스크, CPU, 메모리)에 병목 현상이 있는지 확인합니다.

3. **태스크 디버깅**:
   - 느린 태스크를 추적하여 입력 데이터를 검토하고, 성능 병목 현상을 해결합니다.
   - 태스크 실행 전후의 단계에서 데이터 처리 상태를 확인합니다.

4. **스케줄링 최적화**:
   - 스케줄링 정책을 조정하여 태스크 병렬 처리 성능을 향상시킵니다.

5. **재실행 및 로깅 분석**:
   - 동일한 작업을 여러 번 재실행해 반복적인 패턴과 문제를 파악합니다.
   - 스파크 로그와 스테이지/태스크별 메트릭을 분석하여 문제 원인을 정확히 파악합니다.

### 18.5.5 느린 집계 속도

#### **징후와 증상**
- `groupBy` 호출 시 느린 태스크가 발생합니다.
- 집계 처리 이후에도 전반적인 속도가 느립니다.

#### **잠재적 대응법**
1. **데이터 분배 최적화**:
   - 익스큐터의 메모리를 증가시키거나 데이터 분할 키를 최적화하여 익스큐터 간 데이터 이동을 최소화합니다.
   - 필요 시 데이터를 `repartition`하여 균등하게 분배합니다.

2. **집계 처리 방식 최적화**:
   - 느린 태스크가 특정 노드에 집중되지 않도록 데이터 처리 방식을 변경합니다.
   - 모든 컬럼에 대해 `SELECT` 문을 사용하는 대신, 구조적으로 적절한 컬럼만 집계에 포함시킵니다.

3. **데이터 필터링 및 Null 값 처리**:
   - Null 값을 사전에 필터링하거나 처리 방식(`fill` 또는 `EMPTY` 값 대체 등)을 최적화합니다.

4. **일부 집계 함수 최적화**:
   - 집계 중 사용되는 함수에 따라 성능이 저하될 수 있으므로 최적화된 집계 방법(예: `collect_list` 대신 `collect_set`)을 사용합니다.

---

### 18.5.6 느린 조인 속도

#### **특징**
- 조인과 집계는 모두 데이터 병합 작업을 포함하므로 동일한 원인과 대응책을 가질 수 있습니다.

#### **잠재적 대응법**
1. **데이터 분배 균등화**:
   - 조인 키를 기준으로 데이터를 재분배하여 균등하게 분배되도록 조정합니다.
   - `broadcast join` 사용을 고려해 조인 작업을 효율화합니다.

2. **불필요한 데이터 제거**:
   - 조인 전에 필요한 데이터만 남기고 나머지를 필터링하여 불필요한 데이터 처리 비용을 줄입니다.

3. **조인 유형 최적화**:
   - 작은 데이터셋은 `broadcast` 방식으로 조인하여 성능을 개선합니다.
   - 조인 작업 순서를 재조정하여 효율성을 극대화합니다.

4. **테이블 스키마 확인**:
   - 스키마 불일치로 인한 조인 오류나 성능 저하를 방지하기 위해 테이블 스키마를 점검합니다.

---

### 일반 디버깅 팁
- 데이터가 편중된 경우 데이터 스큐를 확인하고 해결.
- 태스크 실행 중 발생하는 병목 현상을 로그 분석 및 메트릭 확인을 통해 파악.
- 데이터셋의 분배 상태 및 RDD의 파티셔닝을 점검.

효율적인 디버깅을 위해 문제의 원인을 구체적으로 파악한 후, 적절한 대응법을 적용하세요.

### 18.5.9 익스큐터 OutOfMemoryError 또는 응답 없음

#### **징후와 증상**
- 익스큐터 로그에 `OutOfMemoryError` 또는 가비지 컬렉션과 관련된 메시지가 나타남.
- 익스큐터가 비정상적으로 종료되거나 응답하지 않음.
- 특정 노드의 느린 태스크가 복구되지 않음.

#### **잠재적 대응법**
1. **메모리 증설**:
   - 익스큐터의 메모리 설정을 증가시킵니다 (`--executor-memory` 옵션 사용).

2. **병렬 처리 최적화**:
   - 익스큐터가 처리하는 작업의 병렬도를 조정해 부하를 분산합니다.

3. **캐시 관리**:
   - 자주 사용하지 않는 데이터를 캐시에서 제거하여 메모리 사용량을 줄입니다.

4. **GC 설정 최적화**:
   - 가비지 컬렉션의 빈도를 줄이기 위해 JVM 설정을 조정합니다.

5. **데이터 분배 최적화**:
   - 데이터 파티션 수를 조정하거나 적절한 데이터 분배 방식을 사용합니다.

---

### 18.5.10 의도하지 않은 null 값이 있는 결과 데이터

#### **징후와 증상**
- 트랜스포메이션이 실행된 결과에 예상치 못한 `null` 값이 포함됨.
- 잘 동작하던 코드가 예약 작업 또는 환경 변화로 인해 정확한 결과를 생성하지 않음.

#### **잠재적 대응법**
1. **데이터 포맷 변경 여부 확인**:
   - 입력 데이터 포맷이 변경되었는지 확인합니다. 정상적으로 동작하던 코드라도 데이터 스키마 변경으로 인해 `null` 값이 발생할 수 있습니다.

2. **에러 로그 분석**:
   - Spark 로그와 메트릭을 통해 `null` 값이 발생한 트랜스포메이션 단계와 원인을 분석합니다.

3. **데이터 검증 로직 추가**:
   - 트랜스포메이션 실행 전 데이터 스키마를 검증하거나 변환 로직에 추가적인 검증 로직을 삽입합니다.

4. **SQL 캐스팅 문제 해결**:
   - SQL 문장을 사용할 경우 `CAST` 또는 데이터 타입 변환 시 오류가 발생하지 않는지 점검합니다.
   - 예: 문자열 데이터("23")를 숫자 데이터로 변환할 경우 `SELECT * FROM table WHERE column = '23'` 대신 `CAST(column AS INT)`를 명시적으로 사용.

5. **데이터 초기화 처리**:
   - `null` 값 발생 시 초기화 값이나 기본값을 적용하도록 설계합니다 (`fillna` 함수 등 사용).

---

### 추가 디버깅 팁
- Spark UI에서 `null` 발생 시점을 명확히 파악하고 데이터 흐름을 분석합니다.
- 데이터를 소규모로 샘플링하여 단계별로 예상 결과와 비교하며 문제를 진단합니다.

### 18.5.11 디스크 공간 없음 오류

#### **징후와 증상**
- `'no space left on disk'` 오류 메시지와 함께 잡이 실패합니다.

#### **잠재적 대응법**
1. **디스크 공간 확보**:
   - 작업 노드의 디스크 공간을 늘리거나 외부 저장소를 추가합니다.
   - 클라우드 환경에서는 외부 저장소를 활용하여 디스크 공간을 확장할 수 있습니다.

2. **데이터 파티셔닝**:
   - 제한된 용량의 디스크를 사용하는 클러스터에서는 데이터 파티션을 재배치하여 공간 사용을 최적화합니다.

3. **임시 파일 정리**:
   - 장기적으로 남아있는 불필요한 로그 파일이나 임시 파일을 제거합니다.

4. **저장소 설정 점검**:
   - 설정 문제로 인해 디스크 공간이 낭비될 수 있으므로 스파크 공식 문서에서 환경 설정 가이드를 참고합니다.

---

### 18.5.12 직렬화 오류

#### **징후와 증상**
- 직렬화 오류가 발생하면서 잡이 실패합니다.

#### **잠재적 대응법**
1. **UDF 내 데이터 처리 점검**:
   - 사용자 정의 함수(UDF)에서 직렬화되지 않는 객체를 사용하지 않도록 수정합니다.
   - 특히, UDF 내부에서 데이터 타입이나 객체를 명확히 직렬화 가능한 형식으로 변환합니다.

2. **직렬화 라이브러리 변경**:
   - Kryo 직렬화를 활성화하거나 사용자 정의 클래스를 등록하여 스파크에서 인식할 수 있도록 설정합니다:
     ```scala
     spark.conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
     ```

3. **데이터 크기 최적화**:
   - 큰 데이터를 다룰 경우, 적절히 파티션을 나누어 작업의 병렬도를 높입니다.

---

### 18.6 정리

이 장에서는 스파크 잡과 애플리케이션의 **모니터링 및 디버깅**에 사용할 수 있는 주요 도구와 방법을 소개했습니다.  
주요 내용:
- **문제 분석 및 해결**:
  - 스파크 UI, 로그, 메트릭을 통해 단계별로 문제를 진단.
  - 복잡한 소프트웨어를 디버깅할 때는 마찬가지로 원인을 작게 쪼개어 해결.

- **성능 튜닝**:
  - 잡과 태스크의 작업 현황을 빠르게 파악.
  - 데이터 치우침(스큐) 및 직렬화 문제 해결.

다음 장에서는 성능 튜닝과 효율적인 자원 사용을 위한 도구를 다룰 예정입니다.
