# Chapter 19. 성능 튜닝

## **튜닝을 할 수 있는 주요 영역**

- 코드 수준 설계 (RDD or DataFrame)
- 보관용 데이터
- 조인
- 집계
- 데이터 전송
- 애플리케이션 속성
- 익스큐터 프로세스의 JVM
- 워커 노드
- 클러스터와 배포 환경 속성

사용하는 언어에 따라 구성 환경이 많이 달라지므로 언어 선택에 따른 최적화는 의미가 없음.

### **DataFrame vs SQL vs Dataset vs RDD**

- DataFrame / SQL / Dataset은 속도가 동일함.

   - 특히 DataFrame은 어떤 언어에서 사용하더라도 속도에서 큰 차이가 없음.

   - 다만, 파이썬 또는 R을 사용하면 UDF 에서 성능 저하 크게 발생.

- RDD 사용할 때 Kyro 를 사용해서 객체 직렬화하는 것이 중요함.

- 클러스터 자체 성능 모니터링하면서 클러스터 설정을 최적화할 수 있음.

   - 모니터링의 중요성... (관측 가능성)

- 스파크 자원 동적 할당

   - 기본적으로 비활성화지만, 사용자에 의해 활성화 가능. 사용하지 않는 자원 회수에서 다른 리소스에 할당.

- 스케줄링 관한 것

   - `--max-executor-cores`를 최대치로 사용하면 스파크 외에 다른 애플리케이션에서 cpu 자원 사용 못함.

### **보관용 데이터**
   - 조직에서 동일한 데이터셋을 여러 번 활용하여 분석할 필요가 있을 때, 데이터를 효율적으로 보관하는 방법을 고민해야 함.
   - 프로젝트와 시스템의 특성에 맞는 데이터 포맷과 저장소를 선택하는 것이 중요.

### **파일 기반 장기 데이터 저장소**
   - CSV, 바이너리 blob, 아파치 파케이(Parquet) 같은 포맷을 사용하여 장기 데이터 저장 가능.
   - 스파크 작업을 최적화하려면 압축이 가능한 포맷을 선택하는 것이 바람직함.
   - CSV는 구조화된 포맷이지만 속도가 느려 성능 저하가 발생할 수 있음.
   - 파케이는 효율적이며 스파크와 호환성이 좋지만, 사용하지 않는 데이터는 빠르게 건너뛸 수 있도록 저장 방식에 주의해야 함.

### **분할 가능한 파일 포맷과 압축**
   - 데이터를 효율적으로 읽고 처리하려면 분할 가능한 파일 포맷을 선택하는 것이 중요.
   - 분할 가능한 포맷을 사용하면 여러 테스크가 동시에 파일을 읽어 병렬 처리 가능.
   - 압축 방식도 성능에 영향을 미치며, ZIP과 같은 방식은 병렬 처리가 어렵지만, gzip, bzip2 등은 병렬 처리가 가능하여 더 적합함.

### **테이블 파티셔닝**
   - 테이블 파티셔닝은 특정 키(예: 날짜 필드)를 기준으로 개별 테이블처럼 저장하는 방식.
   - 스파크를 비롯한 데이터 스토어에서 지원하며, 필요한 데이터만 효율적으로 읽을 수 있도록 함.
   - 너무 작은 단위로 파티셔닝하면 작은 파일이 많아지고, 이로 인해 저장소 시스템의 성능 저하가 발생할 수 있음.

### **버켓팅**
   - 데이터를 특정 키에 따라 미리 정해진 개수의 그룹으로 나누는 방식.
   - 파티셔닝과 달리, 데이터가 전체적으로 균등하게 분산됨.
   - 특정 키를 자주 조회할 경우 버켓팅을 활용하면 데이터 접근 속도가 향상될 수 있음.
   - 보통 파티셔닝과 함께 사용하여 성능을 더욱 최적화함.


### **파일 수**
   - 데이터 파티셔닝이나 버켓팅을 고려할 때 파일 수를 조정하는 것이 중요.
   - 너무 많은 파일이 존재하면 네트워크 부하와 스케줄링 부담이 증가할 수 있음.
   - 반면, 너무 적은 수의 대용량 파일은 병렬 처리를 방해할 수 있음.
   - 최적의 파일 수를 유지하기 위해 스파크 설정에서 적절한 분할 전략을 활용하는 것이 중요.

### **데이터 지역성**
   - 데이터 지역성(data locality)은 스파크 작업 성능 최적화에 중요한 요소.
   - 데이터가 저장된 노드에서 해당 데이터를 처리할 수 있도록 배치하면 성능이 향상됨.
   - 분산 저장소(HDFS 등)에서 로컬 데이터를 활용하면 네트워크 부하를 줄일 수 있음.
   - 스파크 작업 중 태스크가 'local'로 표시되면 데이터가 해당 노드에서 직접 처리되고 있음을 의미.

### **통계 수집**
   - 스파크의 비용 기반 옵티마이저(CBO)를 효과적으로 활용하려면 테이블 및 컬럼 통계를 수집해야 함.
   - `ANALYZE TABLE table_name COMPUTE STATISTICS` 명령을 사용하여 테이블 단위 통계를 생성할 수 있음.
   - 컬럼 수준의 통계를 수집하려면 `ANALYZE TABLE table_name COMPUTE STATISTICS FOR COLUMNS column_name1, column_name2, ...` 명령을 사용.
   - 컬럼 통계는 조인, 집계, 필터링 등의 최적화에 유용하며, 성능 향상에 기여.
   - 스파크에서 지속적으로 통계 관련 최적화 기능이 추가되고 있음.


### **서블 설정**
   - 스파크의 외부 서블(Shuffle) 서비스는 데이터를 저장하고 읽는 과정에서 중요한 역할을 함.
   - 서블 설정을 통해 클러스터 환경에서 효율적인 데이터 분배 및 노드 간 데이터 이동 최적화 가능.
   - 적절한 직렬화 포맷을 선택하는 것이 중요하며, `Kryo`를 사용하는 것이 권장됨.
   - 파티션 수가 너무 적으면 소수의 노드에 작업이 집중되고, 너무 많으면 오버헤드가 증가함.
   - 서블을 수행할 때, 최적의 결과를 위해 파티션당 최소 수십 MB의 데이터가 포함되는 것이 좋음.

### **메모리 부족과 가비지 컬렉션**
   - 스파크 실행 중 메모리 부족 문제로 인해 작업이 중단될 수 있으며, 이는 다음과 같은 원인 때문:
     1. 애플리케이션이 설정된 메모리 이상을 사용함.
     2. 가비지 컬렉션이 너무 자주 발생하여 성능이 저하됨.
     3. JVM 내에 객체가 너무 많아 가비지 컬렉션이 오버로드됨.
   - 가비지 컬렉션을 최적화하면 스파크 작업 효율을 향상시킬 수 있음.
   - 메모리 부족 문제를 해결하기 위해 구조적 API를 활용하는 방법도 있음.

### **가비지 컬렉션 튜닝**
   - 가비지 컬렉션(GC)은 JVM에서 메모리를 관리하는 중요한 요소이며, 최적화가 필요함.
   - 가비지 컬렉션 프로세스:
     1. Eden 영역에서 객체가 생성됨.
     2. Eden 영역이 가득 차면 `Minor GC`가 실행되어 살아남은 객체를 `Survivor` 영역으로 이동.
     3. `Survivor` 영역이 꽉 차면 오래된 객체는 `Old` 영역으로 이동.
     4. Old 영역이 가득 차면 `Full GC`가 실행되어 불필요한 객체를 정리.
   - `Full GC`는 실행 시간이 길어 성능 저하를 유발할 수 있으므로 최소화해야 함.
   - Young 영역과 Old 영역의 크기 조정을 통해 메모리 사용을 최적화할 수 있음.


### **병렬화**
   - 스파크의 처리 속도를 높이기 위해 병렬성을 극대화하는 것이 중요.
   - `spark.default.parallelism`과 `spark.sql.shuffle.partitions` 값을 클러스터의 CPU 코어 수에 맞춰 설정.
   - 데이터가 많을수록 최소 2~3개의 태스크를 병렬 실행하는 것이 권장됨.

### **향상된 필터링**
   - 스파크는 데이터 필터링을 먼저 수행하면 성능이 향상됨.
   - 가능하면 조인 전에 필터링을 수행하는 것이 가장 효과적.
   - 예를 들어, 조인 전에 3억 개의 결과가 1만 개로 줄어든다면 불필요한 작업이 크게 줄어듦.
   - 파티셔닝과 버켓팅 기법을 함께 사용하면 더욱 최적화 가능.

### **파티션 재분배와 병합**
   - 파티션을 너무 많이 사용하면 오버헤드가 증가하므로, 클러스터 전체적으로 데이터를 균등하게 분배하는 것이 중요.
   - `coalesce`는 기존 파티션 수를 줄이는 데 적합하지만, `repartition`은 데이터 이동이 필요하므로 비용이 더 높음.
   - 조인이나 캐싱을 활용할 경우, 파티션 재분배를 신중히 고려해야 함.

### **사용자 정의 파티셔닝**
   - 기본 파티셔닝보다 더욱 정밀한 데이터 분배를 원할 경우 사용자 정의 파티셔닝을 활용 가능.
   - RDD나 DataFrame 수준에서 직접 정의할 수 있음.
   - 이 방법은 특정 워크로드에는 효과적이지만, 스파크의 자동 최적화 기능이 적용되지 않기 때문에 신중한 설계가 필요.



### **사용자 정의 함수 (UDF) **
   - UDF(User Defined Function)는 데이터를 변환하는 데 사용되지만, JVM 객체로 변환하는 과정에서 성능이 저하될 수 있음.
   - 가능하면 UDF 대신 **구조적 API (SQL, DataFrame, Dataset API)**를 활용하는 것이 좋음.
   - 스파크의 **벡터화(Vectorized) UDF** 기능을 사용하면 Pandas DataFrame처럼 배치 처리할 수 있어 성능 최적화 가능.

### **임시 데이터 저장소 (캐싱)**
   - 동일한 데이터를 여러 번 사용할 경우, **캐싱을 활용하면 성능을 향상**시킬 수 있음.
   - 캐시는 메모리(RAM) 또는 디스크에 저장될 수 있으며, 잘못 사용하면 리소스를 낭비할 수 있음.
   - RDD나 DataFrame을 캐시하면 **다음번 실행 시 디스크에서 다시 로드하는 비용이 절감됨**.
   - 하지만, 캐싱이 **무조건적인 최적화 기법은 아니며, 필요할 때만** 사용해야 함.

### **데이터 캐시 저장소 레벨**
   - 스파크는 다양한 캐시 저장소 옵션을 제공하며, 주요 옵션은 다음과 같음:
     - **MEMORY_ONLY**: 메모리에만 저장, 캐싱이 부족하면 재계산 수행.
     - **MEMORY_AND_DISK**: 메모리에 우선 저장하고, 부족하면 디스크로 저장.
     - **MEMORY_ONLY_SER**: 직렬화하여 메모리에 저장(메모리 절약 가능).
     - **DISK_ONLY**: 데이터를 디스크에만 저장.
     - **OFF_HEAP**: 실행용 메모리에 저장.

   - 데이터 캐시를 활용할 때는 **캐싱이 발생하는 순서를 주의**해야 하며, 캐싱된 데이터가 예상과 다르게 먼저 사용될 수 있음.

### **캐싱된 DataFrame**
   - DataFrame을 캐싱하면 원본 데이터를 다시 읽지 않고, 메모리 또는 디스크에서 데이터를 참조하여 성능을 향상시킴.
   - 캐싱을 활용하면 같은 데이터에 여러 번 접근할 때 반복적인 I/O 비용을 줄일 수 있음.
   - `DF1.cache()`를 실행하면 이후 연산에서 메모리에 저장된 데이터를 활용 가능.

### **캐싱을 활용한 코드 예제**
   - **캐싱을 사용하지 않은 경우**: CSV 파일을 매번 읽고 DataFrame을 생성하여 처리하는 방식은 비효율적.
   - **캐싱을 사용한 경우**: `DF1.cache()`를 실행한 후 연산을 수행하면, 동일한 데이터를 여러 번 처리할 때 속도가 크게 향상됨.
   - `cache()`는 기본적으로 메모리에 저장하지만, 메모리가 부족하면 일부 데이터를 디스크에 저장할 수도 있음.
   - 보다 정교한 캐싱을 위해 `persist(StorageLevel)`을 사용할 수도 있음.

### **조인 최적화**
   - 조인은 성능 최적화를 위한 핵심 작업으로, 적절한 조인 전략을 선택하는 것이 중요.
   - **브로드캐스트 조인(Broadcast Join)**은 작은 테이블을 전체 노드로 배포하여 빠르게 조인할 수 있는 가장 쉬운 최적화 방법.
   - 조인 순서를 변경하는 것만으로도 성능을 크게 개선할 수 있음.
